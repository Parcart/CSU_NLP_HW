{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Загрузка набора данных",
   "id": "e2bedf0d468b270e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T11:38:59.364539Z",
     "start_time": "2025-03-05T11:38:59.357324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "def get_installed_packages():\n",
    "    installed_packages = pkg_resources.working_set\n",
    "    packages = sorted([\"%s==%s\" % (i.key, i.version)\n",
    "                       for i in installed_packages])\n",
    "    return packages\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    packages = get_installed_packages()\n",
    "    if packages:\n",
    "        for package in packages:\n",
    "            print(package)"
   ],
   "id": "5c53539b65705e4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 (main, Feb  4 2025, 14:57:36) [GCC 11.4.0]\n",
      "anyio==4.8.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "argon2-cffi==23.1.0\n",
      "arrow==1.3.0\n",
      "asttokens==3.0.0\n",
      "async-lru==2.0.4\n",
      "attrs==25.1.0\n",
      "babel==2.17.0\n",
      "beautifulsoup4==4.13.3\n",
      "bleach==6.2.0\n",
      "certifi==2025.1.31\n",
      "cffi==1.17.1\n",
      "charset-normalizer==3.4.1\n",
      "comm==0.2.2\n",
      "debugpy==1.8.13\n",
      "decorator==5.2.1\n",
      "defusedxml==0.7.1\n",
      "exceptiongroup==1.2.2\n",
      "executing==2.2.0\n",
      "fastjsonschema==2.21.1\n",
      "fqdn==1.5.1\n",
      "h11==0.14.0\n",
      "httpcore==1.0.7\n",
      "httpx==0.28.1\n",
      "idna==3.10\n",
      "ipykernel==6.29.5\n",
      "ipython==8.33.0\n",
      "ipywidgets==8.1.5\n",
      "isoduration==20.11.0\n",
      "jedi==0.19.2\n",
      "jinja2==3.1.5\n",
      "json5==0.10.0\n",
      "jsonpointer==3.0.0\n",
      "jsonschema-specifications==2024.10.1\n",
      "jsonschema==4.23.0\n",
      "jupyter-client==8.6.3\n",
      "jupyter-console==6.6.3\n",
      "jupyter-core==5.7.2\n",
      "jupyter-events==0.12.0\n",
      "jupyter-lsp==2.2.5\n",
      "jupyter-server-terminals==0.5.3\n",
      "jupyter-server==2.15.0\n",
      "jupyter==1.1.1\n",
      "jupyterlab-pygments==0.3.0\n",
      "jupyterlab-server==2.27.3\n",
      "jupyterlab-widgets==3.0.13\n",
      "jupyterlab==4.3.5\n",
      "markupsafe==3.0.2\n",
      "matplotlib-inline==0.1.7\n",
      "mistune==3.1.2\n",
      "nbclient==0.10.2\n",
      "nbconvert==7.16.6\n",
      "nbformat==5.10.4\n",
      "nest-asyncio==1.6.0\n",
      "notebook-shim==0.2.4\n",
      "notebook==7.3.2\n",
      "overrides==7.7.0\n",
      "packaging==24.2\n",
      "pandocfilters==1.5.1\n",
      "parso==0.8.4\n",
      "pexpect==4.9.0\n",
      "pip==23.2.1\n",
      "platformdirs==4.3.6\n",
      "prometheus-client==0.21.1\n",
      "prompt-toolkit==3.0.50\n",
      "psutil==7.0.0\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.3\n",
      "pycparser==2.22\n",
      "pygments==2.19.1\n",
      "python-dateutil==2.9.0.post0\n",
      "python-json-logger==3.2.1\n",
      "pyyaml==6.0.2\n",
      "pyzmq==26.2.1\n",
      "referencing==0.36.2\n",
      "requests==2.32.3\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986-validator==0.1.1\n",
      "rpds-py==0.23.1\n",
      "send2trash==1.8.3\n",
      "setuptools==68.2.0\n",
      "six==1.17.0\n",
      "sniffio==1.3.1\n",
      "soupsieve==2.6\n",
      "stack-data==0.6.3\n",
      "terminado==0.18.1\n",
      "tinycss2==1.4.0\n",
      "tomli==2.2.1\n",
      "tornado==6.4.2\n",
      "traitlets==5.14.3\n",
      "types-python-dateutil==2.9.0.20241206\n",
      "typing-extensions==4.12.2\n",
      "uri-template==1.3.0\n",
      "urllib3==2.3.0\n",
      "wcwidth==0.2.13\n",
      "webcolors==24.11.1\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.8.0\n",
      "wheel==0.41.2\n",
      "widgetsnbextension==4.0.13\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T11:28:48.128685Z",
     "start_time": "2025-03-05T11:28:48.124953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "%wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz"
   ],
   "id": "e27a240d07f0b06d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:58:52.011908Z",
     "start_time": "2025-03-09T13:58:12.313336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from corus import load_lenta\n",
    "import pandas as pd\n",
    "\n",
    "path = 'lenta-ru-news.csv.gz'\n",
    "records = load_lenta(\n",
    "    path)\n",
    "\n",
    "data = []\n",
    "for record in records:\n",
    "    if record:  # Убедитесь, что запись не None\n",
    "        data.append({\n",
    "            'title': record.title,\n",
    "            'text': record.text,\n",
    "            'topic': record.topic\n",
    "        })\n",
    "df = pd.DataFrame(data)"
   ],
   "id": "3d7eaeb9159ce797",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Подготовка данных",
   "id": "deadb98958c864b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:58:52.062835Z",
     "start_time": "2025-03-09T13:58:52.013576Z"
    }
   },
   "cell_type": "code",
   "source": "df['topic'].value_counts()",
   "id": "7c5a16c0360a3c6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               160519\n",
       "Мир                  136680\n",
       "Экономика             79538\n",
       "Спорт                 64421\n",
       "Культура              53803\n",
       "Бывший СССР           53402\n",
       "Наука и техника       53136\n",
       "Интернет и СМИ        44675\n",
       "Из жизни              27611\n",
       "Дом                   21734\n",
       "Силовые структуры     19596\n",
       "Ценности               7766\n",
       "Бизнес                 7399\n",
       "Путешествия            6408\n",
       "69-я параллель         1268\n",
       "Крым                    666\n",
       "Культпросвет            340\n",
       "                        203\n",
       "Легпром                 114\n",
       "Библиотека               65\n",
       "Оружие                    3\n",
       "ЧМ-2014                   2\n",
       "МедНовости                1\n",
       "Сочи                      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:58:52.126515Z",
     "start_time": "2025-03-09T13:58:52.063911Z"
    }
   },
   "cell_type": "code",
   "source": "df['topic'] = df['topic'].replace('', 'EMPTY')",
   "id": "12a8fee1cc235bf8",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Убираю низкочисленные классификаторы, потому что их влияние будет ровно 0 и количество строк у классификатора, должно быть больше 1.",
   "id": "1d4f8149ca857648"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:58:52.249434Z",
     "start_time": "2025-03-09T13:58:52.128478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "topic_counts = df['topic'].value_counts()\n",
    "min_samples = 5\n",
    "class_df = df[df['topic'].isin(topic_counts[topic_counts >= min_samples].index)]\n",
    "\n",
    "class_df['topic'].value_counts()"
   ],
   "id": "a7ded2ef3ad9a616",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               160519\n",
       "Мир                  136680\n",
       "Экономика             79538\n",
       "Спорт                 64421\n",
       "Культура              53803\n",
       "Бывший СССР           53402\n",
       "Наука и техника       53136\n",
       "Интернет и СМИ        44675\n",
       "Из жизни              27611\n",
       "Дом                   21734\n",
       "Силовые структуры     19596\n",
       "Ценности               7766\n",
       "Бизнес                 7399\n",
       "Путешествия            6408\n",
       "69-я параллель         1268\n",
       "Крым                    666\n",
       "Культпросвет            340\n",
       "EMPTY                   203\n",
       "Легпром                 114\n",
       "Библиотека               65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "На данном этапе, после получение accuracy_score 0,82 на тестовой выборке, я захотел проэксперементировать и постараться распределить весы путем попытки равномерного распределения классификаторов и посмотреть как это может улучшить результат после обучения модели.",
   "id": "94d8baf9541cadac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:56:50.959480Z",
     "start_time": "2025-03-09T13:56:49.776254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "n_classes = class_df['topic'].nunique()\n",
    "target_per_class = 100_000 // n_classes  # Базовый таргет на класс\n",
    "\n",
    "# Собираем данные поровну, не превышая исходное количество\n",
    "balanced_dfs = []\n",
    "for topic in class_df['topic'].unique():\n",
    "    subset = class_df[class_df['topic'] == topic]\n",
    "    if len(subset) > target_per_class:\n",
    "        # Даунсэмплинг для больших классов\n",
    "        balanced_dfs.append(subset.sample(target_per_class, random_state=42))\n",
    "    else:\n",
    "        # Берем все данные для малых классов\n",
    "        balanced_dfs.append(subset)\n",
    "\n",
    "# Собираем и перемешиваем данные\n",
    "balanced_df = pd.concat(balanced_dfs).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Если суммарное количество строк меньше 100K, добавляем недостающее из \"богатых\" классов\n",
    "current_size = len(balanced_df)\n",
    "if current_size < 100_000:\n",
    "    additional_samples = 100_000 - current_size\n",
    "    # Выбираем классы, у которых есть избыток данных\n",
    "    candidates = class_df.groupby('topic').filter(lambda x: len(x) > target_per_class)\n",
    "    # Берем дополнительные образцы (без пересечения с уже выбранными)\n",
    "    additional_df = candidates.sample(n=additional_samples, \n",
    "                                     replace=False, \n",
    "                                     random_state=42)\n",
    "    # Финализируем датафрейм\n",
    "    balanced_df = pd.concat([balanced_df, additional_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Итоговый размер: {len(balanced_df)} строк\")"
   ],
   "id": "78be54501ece4278",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговый размер: 100000 строк\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:56:50.984778Z",
     "start_time": "2025-03-09T13:56:50.961181Z"
    }
   },
   "cell_type": "code",
   "source": "balanced_df['topic'].value_counts()",
   "id": "d2dc6cd64b97f9a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               10904\n",
       "Мир                  10126\n",
       "Экономика             7898\n",
       "Спорт                 7405\n",
       "Наука и техника       7019\n",
       "Бывший СССР           6987\n",
       "Культура              6935\n",
       "Интернет и СМИ        6678\n",
       "Из жизни              6023\n",
       "Дом                   5782\n",
       "Силовые структуры     5757\n",
       "Ценности              5299\n",
       "Бизнес                5270\n",
       "Путешествия           5261\n",
       "69-я параллель        1268\n",
       "Крым                   666\n",
       "Культпросвет           340\n",
       "EMPTY                  203\n",
       "Легпром                114\n",
       "Библиотека              65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T11:03:03.372045Z",
     "start_time": "2025-03-09T11:03:03.364016Z"
    }
   },
   "cell_type": "code",
   "source": "balanced_df",
   "id": "3be4a977de7a7cbb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   title  \\\n",
       "0      В подмосковных Химках обстреляли перевозчиков ...   \n",
       "1       Премию Астрид Линдгрен вручили лауреату \"Оскара\"   \n",
       "2      O1 Properties заинтересовалась бизнес-центром ...   \n",
       "3                      «Газпром» приступил к увольнениям   \n",
       "4      Медальон с прядью волос Джейн Остин выставили ...   \n",
       "...                                                  ...   \n",
       "99995           Астрономы обнаружили планетарные тостеры   \n",
       "99996  Спецназовец оказался слишком женственным для Б...   \n",
       "99997                ЕС выделит Гаити 200 миллионов евро   \n",
       "99998         Суд выселил кота из коммунальной квартиры    \n",
       "99999  Капитан испанской сборной готов пропустить мат...   \n",
       "\n",
       "                                                    text              topic  \n",
       "0      Полиция разыскивает напавших с травматическими...  Силовые структуры  \n",
       "1      Лауреатом премии имени Астрид Линдгрен, котору...           Культура  \n",
       "2      Инвесткомпания O1 Properties ведет переговоры ...                Дом  \n",
       "3      «Газпром» в течение года собирается сократить ...          Экономика  \n",
       "4      Британский аукционный дом Dominic Winter выста...           Культура  \n",
       "...                                                  ...                ...  \n",
       "99995  Астрономы предложили объяснение феномену \"разд...    Наука и техника  \n",
       "99996  Бывшему военнослужащему армии США, офицеру вой...           Из жизни  \n",
       "99997  Европейский союз выделит из своего бюджета 200...                Мир  \n",
       "99998  В Кургане суд постановил выселить из коммуналь...           Из жизни  \n",
       "99999  Капитан сборной Испании и мадридского \"Реала\" ...              Спорт  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В подмосковных Химках обстреляли перевозчиков ...</td>\n",
       "      <td>Полиция разыскивает напавших с травматическими...</td>\n",
       "      <td>Силовые структуры</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Премию Астрид Линдгрен вручили лауреату \"Оскара\"</td>\n",
       "      <td>Лауреатом премии имени Астрид Линдгрен, котору...</td>\n",
       "      <td>Культура</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O1 Properties заинтересовалась бизнес-центром ...</td>\n",
       "      <td>Инвесткомпания O1 Properties ведет переговоры ...</td>\n",
       "      <td>Дом</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>«Газпром» приступил к увольнениям</td>\n",
       "      <td>«Газпром» в течение года собирается сократить ...</td>\n",
       "      <td>Экономика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Медальон с прядью волос Джейн Остин выставили ...</td>\n",
       "      <td>Британский аукционный дом Dominic Winter выста...</td>\n",
       "      <td>Культура</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Астрономы обнаружили планетарные тостеры</td>\n",
       "      <td>Астрономы предложили объяснение феномену \"разд...</td>\n",
       "      <td>Наука и техника</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>Спецназовец оказался слишком женственным для Б...</td>\n",
       "      <td>Бывшему военнослужащему армии США, офицеру вой...</td>\n",
       "      <td>Из жизни</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>ЕС выделит Гаити 200 миллионов евро</td>\n",
       "      <td>Европейский союз выделит из своего бюджета 200...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>Суд выселил кота из коммунальной квартиры</td>\n",
       "      <td>В Кургане суд постановил выселить из коммуналь...</td>\n",
       "      <td>Из жизни</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Капитан испанской сборной готов пропустить мат...</td>\n",
       "      <td>Капитан сборной Испании и мадридского \"Реала\" ...</td>\n",
       "      <td>Спорт</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Решил проверить текст на html разметку и пробежаться по результату, что бы подобрать оптимальные паттерны для обработки текста",
   "id": "58240bc7aac76191"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-05T18:41:56.143570Z",
     "start_time": "2025-03-05T18:41:55.390387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "def check_html_in_column(dframe: pd.DataFrame, column: str, sample_size: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Анализирует колонку DataFrame на наличие HTML-тегов\n",
    "    \"\"\"\n",
    "    html_pattern = re.compile(r'<[^>]+>')\n",
    "    \n",
    "    mask = dframe[column].apply(\n",
    "        lambda x: bool(html_pattern.search(str(x))) if pd.notnull(x) else False\n",
    "    )\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    html_rows = mask.sum()\n",
    "    \n",
    "    result = {\n",
    "        'total_rows': total_rows,\n",
    "        'html_rows': html_rows,\n",
    "        'html_percent': round(html_rows / total_rows * 100, 2) if total_rows > 0 else 0,\n",
    "        'examples': dframe[column][mask].sample(min(sample_size, html_rows)).tolist() if html_rows > 0 else []\n",
    "    }\n",
    "    \n",
    "    if result['html_rows'] > 0:\n",
    "        print(\"\\nПримеры строк с HTML:\")\n",
    "        for example in result['examples']:\n",
    "            print(f\"- {example}...\")\n",
    "\n",
    "check_html_in_column(df, 'text', sample_size=3)"
   ],
   "id": "64a9902ceea11ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Примеры строк с HTML:\n",
      "- Реальная доходность по банковским депозитам россиян в 2011 году будет отрицательной, если рост кредитных портфелей отечественных банков не превысит 5-7 процентов в год. Такое заявление сделал заместитель гендиректора Агентства по страхованию вкладов (АСВ) Андрей Мельников, передает \"Интерфакс\". По всей видимости, Мельников имел в виду отрицательную доходность с учетом инфляции. По словам Мельникова, в случае низкой кредитной активности банки не смогут компенсировать высокие ставки по вкладам, и, следовательно, им придется эти ставки снижать. В то же время в АСВ ожидают, что даже в таких условиях подавляющее большинство населения продолжит \"нести деньги в банки\". За первые шесть месяцев 2010 года объем вкладов россиян увеличился на 12,7 процента и превысил 8,4 триллиона рублей. 25 августа в ЦБ сообщили, что за июль объем депозитов населения в банках России вырос на 2,1 процента и составил более 8,6 триллиона рублей. Согласно прогнозу АСВ, рост вкладов физических лиц в российских кредитных организациях в 2010 году составит 25,5-29,5 процента. Мельников также пояснил, что в настоящий момент вероятность банкротства среднестатистического российского банка даже ниже, чем до кризиса. \"В этом году у нас пока всего шесть страховых случаев <...> выплаты по этим шести случаям составили 450 миллионов рублей против 15,5 миллиарда рублей в острой фазе кризиса. Поэтому сейчас в банковской системе гораздо спокойнее, чем даже в докризисном 2007 году\", - передает РИА Новости слова замгендиректора АСВ....\n",
      "- Пенсионный фонд России (ПФР) будет отслеживать трудовые договоры россиян с помощью технологии блокчейн. Предложения по объединению всех информационных систем фонда в единую цифровую платформу приготовят до конца года. Об этом «Известиям» сообщили в пресс-службе ПФР. При устройстве на работу договор будет заключаться в электронном виде и подтверждаться цифровой подписью. Таким образом, все договоренности будут зафиксированы, а возможность вносить правки будет исключена. «Внедрение смарт-контрактов в трудовые отношения позволит в будущем отказаться от обязательного заключения их в бумажном виде, но иметь о них информацию в любой момент времени, как это сегодня происходит с правом на недвижимость», — заявили в пресс-службе ПФР. Фонд планирует сократить расходы на хранение и обслуживание большого объема данных. «Цифровая платформа ПФР должна стать агрегатором цифровых сервисов в области социального обеспечения населения. <...> [Она] должна, с одной стороны, существенно снизить трансакционные издержки фонда, а с другой — обеспечить его проактивное развитие в условиях цифровизации российской экономики», — отметила пресс-служба. Ранее в июне глава правительства Дмитрий Медведев пояснил, что переход на цифровые трудовые книжки будет постепенным и начнет работать только с 2020 года....\n",
      "- Российская фигуристка Евгения Медведева в интервью YouTube-каналу John Wilson Blades рассказала, в чем разница между Россией и Канадой. «В первую очередь для меня необычно, что все люди здесь практически всегда улыбаются. Когда ты встречаешь кого-то, то тебя обязательно спрашивают: \"Как дела? Как твой день?\". Первое время я не понимала: \"Почему вы у меня все это спрашиваете?\". Это очень необычно. Но я думаю, что это даже лучше для развития, для тренировок. Здесь гораздо спокойнее. Это хорошо», — сказала Медведева. Фигуристка также поделилась впечатлениями от тренировок под руководством нового тренера Брайана Орсера. «Все отличается друг от друга по сравнению с Россией. <...>. Но тренировки с Орсером оставляют позитивное впечатление. Он постоянно просит меня успокоиться», — отметила спортсменка. Медведева прекратила сотрудничество с тренером Этери Тутберидзе в мае 2018-го. После этого фигуристка переехала в Торонто для работы с Орсером. По словам Тутберидзе, до Олимпийских игр-2018 Медведева просила оставить на тот момент 15-летнюю Алину Загитову в юниорах еще на год. В Пхенчхане спортсменка стала обладательницей двух серебряных наград. Золото в женском одиночном катании завоевала Загитова....\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Для работы с venv\n",
    "\n",
    "cd ~/.virtualenvs/csu_nlp_course_hw_1\n",
    "\n",
    "source bin/activate\n",
    "\n",
    "python -m spacy download ru_core_news_sm\n",
    "\n",
    "pip install lxml"
   ],
   "id": "ff28a4a38612b53c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!python -m spacy download ru_core_news_sm",
   "id": "d51e16a7c2fadefd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T13:58:56.570284Z",
     "start_time": "2025-03-09T13:58:55.658123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "class TextProcessing:\n",
    "    def __init__(self, batch_size=100, n_threads=8):\n",
    "        self.batch_size = batch_size\n",
    "        self.n_threads = n_threads\n",
    "        self.nlp = spacy.load(\"ru_core_news_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "    def _clean_text(self, text):\n",
    "        # Удаляем знаки препинания и цифры\n",
    "        return re.sub(r'[^\\w\\s]', ' ', text)\n",
    "\n",
    "    def _process_batch(self, texts):\n",
    "        cleaned_texts = [self._clean_text(text) for text in texts]\n",
    "        lemmatized_texts = []\n",
    "\n",
    "        for doc in self.nlp.pipe(cleaned_texts, batch_size=self.batch_size):\n",
    "            lemmas = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.is_alpha]\n",
    "            lemmatized_texts.append(' '.join(lemmas))\n",
    "\n",
    "        return lemmatized_texts\n",
    "\n",
    "    def process_texts(self, text_series: pd.Series) -> pd.Series:\n",
    "        texts = text_series.tolist()\n",
    "        total = len(texts)\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        results = [None] * total\n",
    "\n",
    "        def process_and_store(start_idx, end_idx):\n",
    "            batch = texts[start_idx:end_idx]\n",
    "            processed_batch = self._process_batch(batch)\n",
    "            return start_idx, processed_batch\n",
    "\n",
    "        futures = []\n",
    "        with ThreadPoolExecutor(max_workers=self.n_threads) as executor:\n",
    "            for start_idx in range(0, total, batch_size):\n",
    "                end_idx = min(start_idx + batch_size, total)\n",
    "                futures.append(executor.submit(process_and_store, start_idx, end_idx))\n",
    "\n",
    "            with tqdm(total=len(futures), desc=\"Processing batches\", leave=True) as pbar:\n",
    "                for future in as_completed(futures):\n",
    "                    start_idx, processed_batch = future.result()\n",
    "                    results[start_idx:start_idx+len(processed_batch)] = processed_batch\n",
    "                    pbar.update(1)\n",
    "\n",
    "        return pd.Series(results, index=text_series.index)\n",
    "    \n",
    "    \n",
    "# df_head = balanced_df.head(2000).copy()\n",
    "processor = TextProcessing(batch_size=200, n_threads=4)\n",
    "# df_head[\"processed_text\"] = processor.process_texts(df_head[\"text\"])\n",
    "# balanced_df[\"processed_text\"] = processor.process_texts(balanced_df[\"text\"])"
   ],
   "id": "e4931cfe973d7030",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T12:24:15.086883Z",
     "start_time": "2025-03-09T11:27:28.798636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "balanced_df[\"processed_text\"] = processor.process_texts(balanced_df[\"text\"])\n",
    "balanced_df[\"processed_title\"] = processor.process_texts(balanced_df[\"title\"])\n",
    "balanced_df.to_csv(\"processed_balanced_text.csv\", index=False, encoding='utf-8')"
   ],
   "id": "a01f6a233ad97fee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Processing batches:   0%|          | 0/500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6970083cf225492396d64699896657c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Processing batches:   0%|          | 0/500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a29fc0cda674d3fa097bf9151b7787d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Разбор pipeline\n",
    "\n",
    "Начать все же хотелось с того, что одно слово из за склонений может иметь множество вариаций, которые могут запутать алгоритм, ведь тогда в его словаре будет допустим 3 слова вместо одного. Для того что бы исправить эту проблему я выбрал библиотеку `spacy `и модель `ru_core_news_sm`, к сожалению мне не удалось установить `spacy[cuda]` и пришлось работать на процессоре, в результате для ускорения производительности был выбран `spacy.pipe` для обработки сразу списка, для ускорения обработка Series запускается в много потоке и на каждый поток выделяется определенный размер batсh что позволило в 3-4 раза ускорить обработку. Для того что бы оптимизировать и ускорить работу лематтизатора, текст был очищен от лишних знаков. В результате чего появился явный минус, что названия компаний или имена разделяются на разные слова, но я и так опаздываю и потратил очень много времени на оптимизацию процесса обработки текста, я не успеваю(.    "
   ],
   "id": "579435e2871b64cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:08:27.443724Z",
     "start_time": "2025-03-09T13:59:00.627022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "100000 / len(class_df)\n",
    "split_df, empty_df = train_test_split(\n",
    "    class_df, train_size=100000 / len(class_df), stratify=class_df['topic']\n",
    ")\n",
    "\n",
    "empty_df = pd.DataFrame()\n",
    "\n",
    "print(len(split_df))\n",
    "\n",
    "processor = TextProcessing(batch_size=200, n_threads=4)\n",
    "split_df[\"processed_text\"] = processor.process_texts(split_df[\"text\"])\n",
    "split_df[\"processed_title\"] = processor.process_texts(split_df[\"title\"])\n",
    "split_df.to_csv(\"processed_split_df.csv\", index=False, encoding='utf-8')"
   ],
   "id": "4096d98d80825ed8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Processing batches:   0%|          | 0/500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "231d1fd549eb43c59507d1b412169a32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Processing batches:   0%|          | 0/500 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ba0eba24b044ffda959424fb0e63ff1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:36:50.366717Z",
     "start_time": "2025-03-09T15:36:50.352218Z"
    }
   },
   "cell_type": "code",
   "source": "split_df['topic'].value_counts()",
   "id": "66f2f4de23547893",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "Россия               21711\n",
       "Мир                  18487\n",
       "Экономика            10758\n",
       "Спорт                 8713\n",
       "Культура              7277\n",
       "Бывший СССР           7223\n",
       "Наука и техника       7187\n",
       "Интернет и СМИ        6043\n",
       "Из жизни              3735\n",
       "Дом                   2940\n",
       "Силовые структуры     2650\n",
       "Ценности              1050\n",
       "Бизнес                1001\n",
       "Путешествия            867\n",
       "69-я параллель         171\n",
       "Крым                    90\n",
       "Культпросвет            46\n",
       "EMPTY                   27\n",
       "Легпром                 15\n",
       "Библиотека               9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Импортирование обработанных датасетов",
   "id": "6dc489f76c59aeb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:58:01.650896Z",
     "start_time": "2025-03-10T10:57:50.006716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "balanced_df = pd.read_csv(\"processed_balanced_text.csv\", encoding='utf-8')\n",
    "split_df = pd.read_csv(\"processed_split_df.csv\", encoding='utf-8')"
   ],
   "id": "ea9b705eec5daf5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Объединяем обработанный текст. И собираем словарь фреймов для удобства.",
   "id": "dfbd72a2dad0c6a4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:58:02.481016Z",
     "start_time": "2025-03-10T10:58:01.652257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "balanced_df.loc[:, 'processed_full_text'] = balanced_df['processed_text'].astype(str) + ' ' + balanced_df['processed_title'].astype(str)\n",
    "split_df.loc[:, 'processed_full_text'] = split_df['processed_text'].astype(str) + ' ' + split_df['processed_title'].astype(str)\n",
    "\n",
    "df_balanced_cleaned = balanced_df.loc[~balanced_df['topic'].isin(['EMPTY', 'Библиотека', \"Легпром\"])].copy()\n",
    "df_split_cleaned = split_df.loc[~split_df['topic'].isin(['EMPTY', 'Библиотека', \"Легпром\"])].copy()\n",
    "\n",
    "\n",
    "data_dfs = {\n",
    "    \"balanced_df\" : {\"df\": balanced_df},\n",
    "    \"split_df\" : {\"df\": split_df},\n",
    "    \"df_balanced_cleaned\" : {\"df\": df_balanced_cleaned},\n",
    "    \"df_split_cleaned\" : {\"df\": df_split_cleaned}\n",
    "}\n",
    "\n",
    "for name, data in data_dfs.items():\n",
    "    frame = data[\"df\"]\n",
    "\n",
    "    train_df, temp_df = train_test_split(\n",
    "        frame, test_size=0.4, stratify=frame['topic']\n",
    "    )\n",
    "    \n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df, test_size=0.5, stratify=temp_df['topic']\n",
    "    )\n",
    "    \n",
    "    data[\"train_df\"] = train_df\n",
    "    data[\"val_df\"] = val_df\n",
    "    data[\"test_df\"] = test_df\n"
   ],
   "id": "b4decedb0f9c14cd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:58:02.586343Z",
     "start_time": "2025-03-10T10:58:02.482544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for name, data in data_dfs.items():\n",
    "    \n",
    "    train_df = data[\"train_df\"]\n",
    "    val_df = data[\"val_df\"]\n",
    "\n",
    "    X_train = train_df['processed_full_text']\n",
    "    y_train = train_df['topic']\n",
    "    \n",
    "    X_val = val_df['processed_full_text']\n",
    "    y_val = val_df['topic']\n",
    "    \n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "    y_val_pred = dummy_clf.predict(X_val)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"Базовое качество DummyClassifier {name} (most_frequent): {accuracy:.4f}\")"
   ],
   "id": "15f0e58bdead0691",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Базовое качество DummyClassifier balanced_df (most_frequent): 0.1090\n",
      "Базовое качество DummyClassifier split_df (most_frequent): 0.2171\n",
      "Базовое качество DummyClassifier df_balanced_cleaned (most_frequent): 0.1095\n",
      "Базовое качество DummyClassifier df_split_cleaned (most_frequent): 0.2173\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проверяем фреймы на пустые значения и получаем, что Proccess текст уничтожил одну строку текст, уберем её и пойдем дальше.",
   "id": "8ddd61f497bd9b10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:58:02.701455Z",
     "start_time": "2025-03-10T10:58:02.587828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(split_df.isna().any().any())\n",
    "print(balanced_df.isna().any().any())\n",
    "print(df_balanced_cleaned.isna().any().any())\n",
    "print(df_split_cleaned.isna().any().any())\n"
   ],
   "id": "377a6a90477660bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:58:02.897113Z",
     "start_time": "2025-03-10T10:58:02.702625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "split_df.dropna(inplace=True)\n",
    "balanced_df.dropna(inplace=True)\n",
    "df_balanced_cleaned.dropna(inplace=True)\n",
    "df_split_cleaned.dropna(inplace=True)"
   ],
   "id": "671b9bf6ab41e4c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:43:46.294832Z",
     "start_time": "2025-03-10T10:43:46.283608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(split_df['topic'].value_counts())\n",
    "print(balanced_df['topic'].value_counts())"
   ],
   "id": "330472c82b3f41ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic\n",
      "Россия               21710\n",
      "Мир                  18487\n",
      "Экономика            10758\n",
      "Спорт                 8713\n",
      "Культура              7277\n",
      "Бывший СССР           7223\n",
      "Наука и техника       7187\n",
      "Интернет и СМИ        6043\n",
      "Из жизни              3735\n",
      "Дом                   2940\n",
      "Силовые структуры     2650\n",
      "Ценности              1050\n",
      "Бизнес                1001\n",
      "Путешествия            867\n",
      "69-я параллель         171\n",
      "Крым                    90\n",
      "Культпросвет            46\n",
      "EMPTY                   27\n",
      "Легпром                 15\n",
      "Библиотека               9\n",
      "Name: count, dtype: int64\n",
      "topic\n",
      "Россия               10904\n",
      "Мир                  10126\n",
      "Экономика             7898\n",
      "Спорт                 7405\n",
      "Наука и техника       7019\n",
      "Бывший СССР           6987\n",
      "Культура              6935\n",
      "Интернет и СМИ        6678\n",
      "Из жизни              6023\n",
      "Дом                   5782\n",
      "Силовые структуры     5757\n",
      "Ценности              5299\n",
      "Бизнес                5270\n",
      "Путешествия           5261\n",
      "69-я параллель        1268\n",
      "Крым                   666\n",
      "Культпросвет           340\n",
      "EMPTY                  203\n",
      "Легпром                114\n",
      "Библиотека              65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Проверяем что мы не потеряли ни один классификатор во всех фреймах, которые будем использовать для обучения.",
   "id": "b92767262cff755f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:49:19.375325Z",
     "start_time": "2025-03-10T10:49:19.363790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(data_dfs[\"balanced_df\"][\"test_df\"]['topic'].value_counts()))\n",
    "print(len(data_dfs[\"balanced_df\"][\"train_df\"]['topic'].value_counts()))\n",
    "print(len(data_dfs[\"balanced_df\"][\"val_df\"]['topic'].value_counts()))\n",
    "print(len(data_dfs[\"split_df\"][\"test_df\"]['topic'].value_counts()))\n",
    "print(len(data_dfs[\"split_df\"][\"train_df\"]['topic'].value_counts()))\n",
    "print(len(data_dfs[\"split_df\"][\"val_df\"]['topic'].value_counts()))"
   ],
   "id": "9bc13bd666239741",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "669c6d78a146c96f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Подготовив все данные приступлю к обучению модели `LogisticRegression`. Для настроек `TfidfVectorizer` я выбрал триграммы, потому что работаем с большим количеством документов и со среднем объёмом текстов. Я не стал устанавливать параметр max_features, потому что хоть это и может значительно ускорить обучение, но я выполнил лематизацию и урезание матрицы при помощи max_features нигативно сказывается на результате, оптимально минимальным параметром можно выставить значение 10000, на моих данных данное значение параметра показывает максимальный результат между скоростью и качеством, в скорости 2-3 раза, в качестве, 0,15. Так же из-за низкочисленных классификаторов таких как \"EMPTY\" и \"Библиотека\" необходимо установить умеренную регуляризацию `C=10`, иначе модель отказывается обучиться и показывает f1 0 на этих классификаторах.\n",
    "\n",
    "Использование ngram_range=(1, 3) позволило модели учитывать контекст. Параметры min_df=5 и max_df=0.9 помогли отфильтровать редкие и слишком частые токены, что также улучшило результаты."
   ],
   "id": "ddf9dc6016689d63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:38:25.586330Z",
     "start_time": "2025-03-10T10:33:59.137185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "dataframe_train = data_dfs[\"balanced_df\"][\"train_df\"]\n",
    "dataframe_val = data_dfs[\"balanced_df\"][\"val_df\"]\n",
    "dataframe_test = data_dfs[\"balanced_df\"][\"test_df\"]\n",
    "\n",
    "y_train = dataframe_train['topic']\n",
    "y_val = dataframe_val['topic']\n",
    "y_test = dataframe_test['topic']\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=5,\n",
    "        max_df=0.9,\n",
    "        )\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(dataframe_train['processed_full_text'])\n",
    "X_val_vect = vectorizer.transform(dataframe_val['processed_full_text'])\n",
    "X_test_vect = vectorizer.transform(dataframe_test['processed_full_text'])\n",
    "\n",
    "model = LogisticRegression(\n",
    "        max_iter=10000, # ConvergenceWarning\n",
    "        C = 10,\n",
    "        n_jobs=-1,\n",
    "        )\n",
    "\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "# Проверка на валидации\n",
    "y_val_pred = model.predict(X_val_vect)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"\\nКачество LogisticRegression с TfidfVectorizer на валидации: {val_accuracy:.4f}\")\n",
    "\n",
    "# Проверка на тестовой выборке\n",
    "y_test_pred = model.predict(X_test_vect)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Качество LogisticRegression с TfidfVectorizer на тестовой выборке: {test_accuracy:.4f}\")\n",
    "\n",
    "# Отчёт по классам\n",
    "print(\"\\nClassification report на тесте с TfidfVectorizer:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ],
   "id": "465411a2e69cc2cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Качество LogisticRegression с TfidfVectorizer на валидации: 0.8183\n",
      "Качество LogisticRegression с TfidfVectorizer на тестовой выборке: 0.8154\n",
      "\n",
      "Classification report на тесте с TfidfVectorizer:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.90      0.73      0.81       254\n",
      "            EMPTY       1.00      0.20      0.33        40\n",
      "       Библиотека       1.00      0.31      0.47        13\n",
      "           Бизнес       0.78      0.78      0.78      1054\n",
      "      Бывший СССР       0.86      0.84      0.85      1397\n",
      "              Дом       0.89      0.88      0.88      1156\n",
      "         Из жизни       0.70      0.71      0.71      1205\n",
      "   Интернет и СМИ       0.79      0.76      0.77      1336\n",
      "             Крым       0.77      0.65      0.70       133\n",
      "    Культпросвет        0.88      0.53      0.66        68\n",
      "         Культура       0.85      0.87      0.86      1387\n",
      "          Легпром       0.83      0.43      0.57        23\n",
      "              Мир       0.74      0.79      0.77      2025\n",
      "  Наука и техника       0.85      0.84      0.84      1404\n",
      "      Путешествия       0.88      0.87      0.87      1052\n",
      "           Россия       0.71      0.76      0.74      2181\n",
      "Силовые структуры       0.78      0.75      0.76      1151\n",
      "            Спорт       0.96      0.96      0.96      1481\n",
      "         Ценности       0.94      0.92      0.93      1060\n",
      "        Экономика       0.82      0.80      0.81      1580\n",
      "\n",
      "         accuracy                           0.82     20000\n",
      "        macro avg       0.85      0.72      0.75     20000\n",
      "     weighted avg       0.82      0.82      0.82     20000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Предположив, что EMPTY является классификатором, который обозначаниет что у статьи нету темы, я решил его убрать и так же убрать низкочисленные классификаторы такие как \"Легпром\" и \"Библиотека\". Качество предсказания модели улучшилось на 0,1 при `С=1`",
   "id": "1035a9d8297abbcd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T10:52:52.128515Z",
     "start_time": "2025-03-10T10:50:47.797612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataframe_train = data_dfs[\"df_balanced_cleaned\"][\"train_df\"]\n",
    "dataframe_val = data_dfs[\"df_balanced_cleaned\"][\"val_df\"]\n",
    "dataframe_test = data_dfs[\"df_balanced_cleaned\"][\"test_df\"]\n",
    "\n",
    "y_train = dataframe_train['topic']\n",
    "y_val = dataframe_val['topic']\n",
    "y_test = dataframe_test['topic']\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=5,\n",
    "        max_df=0.9,\n",
    "        )\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(dataframe_train['processed_full_text'])\n",
    "X_val_vect = vectorizer.transform(dataframe_val['processed_full_text'])\n",
    "X_test_vect = vectorizer.transform(dataframe_test['processed_full_text'])\n",
    "\n",
    "model = LogisticRegression(\n",
    "        n_jobs=-1,\n",
    "        max_iter=10000, # ConvergenceWarning\n",
    "        )\n",
    "\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "# Проверка на валидации\n",
    "y_val_pred = model.predict(X_val_vect)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"\\nКачество LogisticRegression с TfidfVectorizer на валидации: {val_accuracy:.4f}\")\n",
    "\n",
    "# Проверка на тестовой выборке\n",
    "y_test_pred = model.predict(X_test_vect)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Качество LogisticRegression с TfidfVectorizer на тестовой выборке: {test_accuracy:.4f}\")\n",
    "\n",
    "# Отчёт по классам\n",
    "print(\"\\nClassification report на тесте с TfidfVectorizer:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ],
   "id": "951081231d7460a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Качество LogisticRegression с TfidfVectorizer на валидации: 0.8072\n",
      "Качество LogisticRegression с TfidfVectorizer на тестовой выборке: 0.8056\n",
      "\n",
      "Classification report на тесте с TfidfVectorizer:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.93      0.66      0.77       253\n",
      "           Бизнес       0.81      0.76      0.78      1054\n",
      "      Бывший СССР       0.82      0.85      0.83      1397\n",
      "              Дом       0.86      0.84      0.85      1157\n",
      "         Из жизни       0.70      0.70      0.70      1205\n",
      "   Интернет и СМИ       0.77      0.76      0.77      1335\n",
      "             Крым       0.81      0.59      0.69       133\n",
      "    Культпросвет        0.74      0.25      0.37        68\n",
      "         Культура       0.85      0.88      0.86      1387\n",
      "              Мир       0.74      0.79      0.77      2026\n",
      "  Наука и техника       0.83      0.82      0.83      1404\n",
      "      Путешествия       0.86      0.83      0.85      1052\n",
      "           Россия       0.69      0.76      0.73      2181\n",
      "Силовые структуры       0.76      0.72      0.74      1152\n",
      "            Спорт       0.95      0.96      0.96      1481\n",
      "         Ценности       0.94      0.91      0.92      1060\n",
      "        Экономика       0.80      0.80      0.80      1579\n",
      "\n",
      "         accuracy                           0.81     19924\n",
      "        macro avg       0.82      0.76      0.78     19924\n",
      "     weighted avg       0.81      0.81      0.81     19924\n",
      "\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Подбор параметров",
   "id": "c2254860039ec4ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Начнем подбор парметров. C=10, C=50: Постепенное уменьшение регуляризации, чтобы модель могла лучше подстроиться под данные. max_iter=10000 и max_iter=15000 — это большие значения, которые гарантируют, что модель успеет сойтись даже на сложных данных, потому что 1000 и 5000 не хватает и в малочисленных классификаторах я получаю f1 = 0. Использую `balanced` из за, что данные несбалансированы, хоть я и попытался равномерно их распределить, но все равно этого не достаточно, что бы назвать его сбалансированным. \n",
    "\n",
    "Оставил `penalty=l2`, потому что `solver=lbfgs` поддерживает только его. ``lbfgs`` хорошо подходит для данных с умеренным количеством признаков и более быстрый.\n",
    "\n",
    "Так же у меня к сожалению не получилось подобрать параметры к saga, хоть он и должен показывать себя лучше на больших объёмах данных, но я прожал 3 часа, но так и получил результат по `GridSearchCV`.\n",
    "\n",
    "Так же я установил `max_features=10000`, что конечно повлияет на результат, но зачительно ускорит подборк."
   ],
   "id": "292891335747353"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T14:23:01.065339Z",
     "start_time": "2025-03-10T14:20:44.813056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def grid_search(vectorizer, data):\n",
    "    param_grid = {\n",
    "    'C': [10, 50],\n",
    "    'max_iter': [10000, 7500, 12500],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'class_weight': ['balanced'],\n",
    "    }   \n",
    "\n",
    "    logreg = LogisticRegression(\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        logreg,\n",
    "        param_grid,\n",
    "        cv=3,  # кросс-валидация по 3 фолдам, ну чуть быстрее.\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    dataframe_train = data[\"train_df\"]\n",
    "    dataframe_val = data[\"val_df\"]\n",
    "    dataframe_test = data[\"test_df\"]\n",
    "    \n",
    "    y_train = dataframe_train['topic']\n",
    "    y_val = dataframe_val['topic']\n",
    "    y_test = dataframe_test['topic']\n",
    "\n",
    "    X_train_vect = vectorizer.fit_transform(dataframe_train['processed_full_text'])\n",
    "    X_val_vect = vectorizer.transform(dataframe_val['processed_full_text'])\n",
    "    X_test_vect = vectorizer.transform(dataframe_test['processed_full_text'])\n",
    "    \n",
    "    grid_search.fit(X_train_vect, y_train)\n",
    "    \n",
    "    print(f\"\\nЛучшие параметры: {grid_search.best_params_}\")\n",
    "    print(f\"Лучшее качество на кросс-валидации: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Оценка на валидации с лучшей моделью\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_val_pred = best_model.predict(X_val_vect)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"\\nКачество на валидации с лучшими параметрами: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Финальная проверка на тесте\n",
    "    y_test_pred = best_model.predict(X_test_vect)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(f\"\\nКачество на тестовой выборке: {test_accuracy:.4f}\")\n",
    "    \n",
    "    # Отчёт по классам\n",
    "    print(\"\\nClassification report на тесте:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "grid_search(TfidfVectorizer(\n",
    "        max_features=10000,\n",
    "        ngram_range=(1, 3),\n",
    "        min_df=5,\n",
    "        max_df=0.9,\n",
    "        ), data_dfs[\"balanced_df\"])\n",
    "\n",
    "    "
   ],
   "id": "22e690d3ebaa91bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      "Лучшие параметры: {'C': 10, 'class_weight': 'balanced', 'max_iter': 10000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Лучшее качество на кросс-валидации: 0.8010\n",
      "\n",
      "Качество на валидации с лучшими параметрами: 0.8063\n",
      "\n",
      "Качество на тестовой выборке: 0.8105\n",
      "\n",
      "Classification report на тесте:\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "   69-я параллель       0.83      0.86      0.85       253\n",
      "            EMPTY       0.35      0.17      0.23        40\n",
      "       Библиотека       1.00      0.85      0.92        13\n",
      "           Бизнес       0.76      0.79      0.78      1054\n",
      "      Бывший СССР       0.83      0.86      0.85      1397\n",
      "              Дом       0.88      0.87      0.88      1157\n",
      "         Из жизни       0.68      0.73      0.70      1205\n",
      "   Интернет и СМИ       0.78      0.77      0.78      1336\n",
      "             Крым       0.69      0.80      0.75       133\n",
      "    Культпросвет        0.58      0.66      0.62        68\n",
      "         Культура       0.87      0.86      0.86      1387\n",
      "          Легпром       0.71      0.65      0.68        23\n",
      "              Мир       0.76      0.75      0.76      2025\n",
      "  Наука и техника       0.83      0.81      0.82      1404\n",
      "      Путешествия       0.86      0.87      0.87      1052\n",
      "           Россия       0.74      0.71      0.73      2181\n",
      "Силовые структуры       0.73      0.77      0.75      1151\n",
      "            Спорт       0.95      0.96      0.96      1481\n",
      "         Ценности       0.94      0.94      0.94      1060\n",
      "        Экономика       0.82      0.79      0.80      1580\n",
      "\n",
      "         accuracy                           0.81     20000\n",
      "        macro avg       0.78      0.77      0.77     20000\n",
      "     weighted avg       0.81      0.81      0.81     20000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T14:43:49.376472Z",
     "start_time": "2025-03-10T14:28:40.128495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Настройки векторизаторов\n",
    "vectorizers = {\n",
    "    'CountVectorizer': \"\",\n",
    "    'TfidfVectorizer': \"\"\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, vectorizer in tqdm(vectorizers.items(), desc=\"Векторизаторы\"):\n",
    "    if name == \"CountVectorizer\":\n",
    "        vectorizer = CountVectorizer(\n",
    "        \n",
    "        ngram_range=(1, 3),\n",
    "        min_df=5,\n",
    "        max_df=0.9\n",
    "    )\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer(\n",
    "        \n",
    "        ngram_range=(1, 3),\n",
    "        min_df=5,\n",
    "        max_df=0.9,\n",
    "        sublinear_tf=True\n",
    "    )\n",
    "    print(f\"\\n{name}:\")\n",
    "    for name, data in data_dfs.items():\n",
    "        print(f\"frame: {name}\")\n",
    "        \n",
    "        dataframe_train = data[\"train_df\"]\n",
    "        dataframe_val = data[\"val_df\"]\n",
    "        dataframe_test = data[\"test_df\"]\n",
    "        \n",
    "        y_train = dataframe_train['topic']\n",
    "        y_val = dataframe_val['topic']\n",
    "        y_test = dataframe_test['topic']\n",
    "\n",
    "        X_train_vect = vectorizer.fit_transform(dataframe_train['processed_full_text'])\n",
    "        X_val_vect = vectorizer.transform(dataframe_val['processed_full_text'])\n",
    "        X_test_vect = vectorizer.transform(dataframe_test['processed_full_text'])\n",
    "    \n",
    "        model = LogisticRegression(\n",
    "            C=10,\n",
    "            penalty='l2',\n",
    "            class_weight='balanced',\n",
    "            max_iter=10000,\n",
    "            solver='lbfgs',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_train_vect, y_train)\n",
    "    \n",
    "        # Предсказания\n",
    "        y_val_pred = model.predict(X_val_vect)\n",
    "        y_test_pred = model.predict(X_test_vect)\n",
    "    \n",
    "        # Метрики\n",
    "        val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        \n",
    "        print(f\"  Валидация: {val_accuracy:.4f}\")\n",
    "        print(f\"  Тест: {test_accuracy:.4f}\")\n",
    "        \n",
    "        # Сохраняем результаты\n",
    "        results[name] = {\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'classification_report': classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)\n",
    "        }"
   ],
   "id": "cf144bdf7f3b5dec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Векторизаторы:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50c71db6217042baad0defa59733dd11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CountVectorizer:\n",
      "frame: balanced_df\n",
      "  Валидация: 0.8092\n",
      "  Тест: 0.8113\n",
      "frame: split_df\n",
      "  Валидация: 0.8102\n",
      "  Тест: 0.8139\n",
      "frame: df_balanced_cleaned\n",
      "  Валидация: 0.8134\n",
      "  Тест: 0.8169\n",
      "frame: df_split_cleaned\n",
      "  Валидация: 0.8131\n",
      "  Тест: 0.8165\n",
      "\n",
      "TfidfVectorizer:\n",
      "frame: balanced_df\n",
      "  Валидация: 0.8286\n",
      "  Тест: 0.8306\n",
      "frame: split_df\n",
      "  Валидация: 0.8293\n",
      "  Тест: 0.8268\n",
      "frame: df_balanced_cleaned\n",
      "  Валидация: 0.8324\n",
      "  Тест: 0.8339\n",
      "frame: df_split_cleaned\n",
      "  Валидация: 0.8286\n",
      "  Тест: 0.8312\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`TfidfVectorizer` показал себя лучше, чем `CountVectorizer`, во всех случаях. Это связано с тем, что TfidfVectorizer учитывает не только частоту слов, но и их важность в контексте всего документа, что позволяет лучше выделять значимые признаки.\n",
    "\n",
    "Попытка равномерно распределить данные (balanced_df) показала результаты, близкие к несбалансированным (split_df), но после удаления классификаторов с низкой значимостью качество модели немного улучшилось.\n",
    "\n",
    "\n",
    "balanced_df: accuracy на тесте — 0.8306.\n",
    "df_balanced_cleaned: accuracy на тесте — 0.8339.\n",
    "\n",
    "В итоге удаление малоинформативных классов помогает модели лучше обобщать, конечно не значительно, но результат есть.\n",
    "\n",
    "Модель демонстрирует стабильность на валидационной и тестовой выборках, что говорит об отсутствии переобучения.\n",
    "\n",
    "Очистка данных и более равномерное распределение классов положительно влияют на качество модели."
   ],
   "id": "2ec52d39aed2be72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
